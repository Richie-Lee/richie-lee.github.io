[{"author":null,"categories":["Projects"],"content":"This post covers Bayesian A/B Testing, an alternative solution to traditional sequential A/B testing methods that strives to optimise cost-efficiency of experiments while preserving strength of evidence collected. To demonstrate and explain the basic concept, readers are referred to the brief introduction and simple implementation (Jupyter Notebook) further down below.","date":1680307200,"description":"This post covers Bayesian A/B Testing, an alternative solution to traditional sequential A/B testing methods that strives to optimise cost-efficiency of experiments while preserving strength of evidence collected. To demonstrate and explain the basic concept, readers are referred to the brief introduction and simple implementation (Jupyter Notebook) further down below.","dir":"post\\","excerpt_html":"This post covers Bayesian A/B Testing, an alternative solution to traditional sequential A/B testing methods that strives to optimise cost-efficiency of experiments while preserving strength of evidence collected. To demonstrate and explain the basic concept, readers are referred to the brief introduction and simple implementation (Jupyter Notebook) further down below.","excerpt_text":"This post covers Bayesian A/B Testing, an alternative solution to traditional sequential A/B testing methods that strives to optimise cost-efficiency of experiments while preserving strength of evidence collected. To demonstrate and explain the basic concept, readers are referred to the brief introduction and simple implementation (Jupyter Notebook) further down below.","expirydate":-62135596800,"fuzzywordcount":2500,"html":"This post covers Bayesian A/B Testing, an alternative solution to traditional sequential A/B testing methods that strives to optimise cost-efficiency of experiments while preserving strength of evidence collected. To demonstrate and explain the basic concept, readers are referred to the brief introduction and simple implementation (Jupyter Notebook) further down below.","keywords":null,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"100c5dd9c48b0eeb39418168da25b955","permalink":"/post/2023_bayesian_ab_testing/","publishdate":"2023-04-01T00:00:00Z","readingtime":12,"relpermalink":"/post/2023_bayesian_ab_testing/","section":"post","summary":"TL:DR This post covers Bayesian A/B Testing, an alternative solution to designing cost-efficient experiments while preserving strength of evidence. To demonstrate and explain the basic concept, readers are referred to the brief introduction and simple implementation (Jupyter Notebook) further down below. Feel free to play around with the actual thing following the link here.\nIntroduction A/B testing has become a cornerstone in the digital age for identifying and measuring causal effects.","tags":["A/B Testing","Bayesian Statistics","Causal inference","Classification","Econometrics","Experimentation","Industry"],"title":"Bayesian A/B Testing with Early Stopping: JustEatTakeaway.com","type":"post","url":"/post/2023_bayesian_ab_testing/","weight":0,"wordcount":2439},{"author":null,"categories":["Projects"],"content":"This study explores the dynamics between product labels and consumer buying behaviour and successfully addressed the challenges posed by panel data, such as unobserved heterogeneity, omitted variable bias by leveraging Micro-Econometric techniques. The positive reception of the findings and methodologies led to an invitation to present the results at Albert Heijn's Data Science department's Knowledge Exchange initiative.","date":1651363200,"description":"This study explores the dynamics between product labels and consumer buying behaviour and successfully addressed the challenges posed by panel data, such as unobserved heterogeneity, omitted variable bias by leveraging Micro-Econometric techniques. The positive reception of the findings and methodologies led to an invitation to present the results at Albert Heijn's Data Science department's Knowledge Exchange initiative.","dir":"post\\","excerpt_html":"This study explores the dynamics between product labels and consumer buying behaviour and successfully addressed the challenges posed by panel data, such as unobserved heterogeneity, omitted variable bias by leveraging Micro-Econometric techniques. The positive reception of the findings and methodologies led to an invitation to present the results at Albert Heijn's Data Science department's Knowledge Exchange initiative.","excerpt_text":"This study explores the dynamics between product labels and consumer buying behaviour and successfully addressed the challenges posed by panel data, such as unobserved heterogeneity, omitted variable bias by leveraging Micro-Econometric techniques. The positive reception of the findings and methodologies led to an invitation to present the results at Albert Heijn's Data Science department's Knowledge Exchange initiative.","expirydate":-62135596800,"fuzzywordcount":1800,"html":"This study explores the dynamics between product labels and consumer buying behaviour and successfully addressed the challenges posed by panel data, such as unobserved heterogeneity, omitted variable bias by leveraging Micro-Econometric techniques. The positive reception of the findings and methodologies led to an invitation to present the results at Albert Heijn's Data Science department's Knowledge Exchange initiative.","keywords":null,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"1acc50ba8f0c7324ee85b3198d6f07c3","permalink":"/post/2022_heterogeneity_ah/","publishdate":"2022-05-01T00:00:00Z","readingtime":9,"relpermalink":"/post/2022_heterogeneity_ah/","section":"post","summary":"TL:DR In collaboration with Albert Heijn, this study explores the dynamics between product labels and consumer buying behaviour. The study successfully addressed the challenges posed by panel data, such as unobserved heterogeneity, omitted variable bias, and seasonality, demonstrating the usefulness of the micro-econometric toolkit.\nThe positive reception of the findings and methodologies led to an invitation to present the results at Albert Heijn\u0026rsquo;s Data Science department\u0026rsquo;s Knowledge Exchange initiative. The main contribution of the study is the proof-of-concept and simplifiction of micro-econometric methods for these specific use-cases.","tags":["Causal Inference","Clustering","Data Science","Econometrics","Forecasting","Industry","Panel Data","Regression"],"title":"Econometric Panel Data Modelling: Albert Heijn (Ahold Delhaize)","type":"post","url":"/post/2022_heterogeneity_ah/","weight":0,"wordcount":1712},{"author":null,"categories":["Projects"],"content":"This post applies Uplift modelling in Python, using causal inference and personalization (XGBoost), to optimize ROI for an A/B/n tested marketing campaign. The results identify the target audience for maximum positive conversions while minimizing costs and campaign-caused churn. ","date":1643673600,"description":"This post applies Uplift modelling in Python, using causal inference and personalization (XGBoost), to optimize ROI for an A/B/n tested marketing campaign. The results identify the target audience for maximum positive conversions while minimizing costs and campaign-caused churn. ","dir":"post\\","excerpt_html":"This post applies Uplift modelling in Python, using causal inference and personalization (XGBoost), to optimize ROI for an A/B/n tested marketing campaign. The results identify the target audience for maximum positive conversions while minimizing costs and campaign-caused churn. ","excerpt_text":"This post applies Uplift modelling in Python, using causal inference and personalization (XGBoost), to optimize ROI for an A/B/n tested marketing campaign. The results identify the target audience for maximum positive conversions while minimizing costs and campaign-caused churn. ","expirydate":-62135596800,"fuzzywordcount":1300,"html":"This post applies Uplift modelling in Python, using causal inference and personalization (XGBoost), to optimize ROI for an A/B/n tested marketing campaign. The results identify the target audience for maximum positive conversions while minimizing costs and campaign-caused churn. ","keywords":null,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"ef7e52d1b1b8e960b3fb9228951decf5","permalink":"/post/2021_uplift/","publishdate":"2022-02-01T00:00:00Z","readingtime":7,"relpermalink":"/post/2021_uplift/","section":"post","summary":"TL:DR This post cover an application of Uplift modelling, a methodology that leverages causal inference insights alongside personalisation techniques (XGBoost) to optimise ROI on, in this case, an A/B/n tested marketing campaign. The experiment results can be used to identify target audience to maximise positive conversion and to minimise corresponding costs and campaign-caused churns.\nContext When considering targeted campaigns one of the most important questions to ask is, Who is our intended audience?","tags":["A/B Testing","Causal Inference","Data Science","Experimentation","Forecasting","Machine Learning","Uplift"],"title":"Uplift Modelling: Personalising Discount Campaigns","type":"post","url":"/post/2021_uplift/","weight":0,"wordcount":1291},{"author":null,"categories":["Projects"],"content":"This study investigates compression and detection of complex data relations in big data through Dutch House-Price forecasting using PCA, Independent Component Analysis, Sparse PCA alongside machine learning based techniques such as XGBoost \u0026 Elastic Nets. Potential of mixture models is also explore through mean model combinations. ","date":1622505600,"description":"This study investigates compression and detection of complex data relations in big data through Dutch House-Price forecasting using PCA, Independent Component Analysis, Sparse PCA alongside machine learning based techniques such as XGBoost \u0026 Elastic Nets. Potential of mixture models is also explore through mean model combinations. ","dir":"post\\","excerpt_html":"This study investigates compression and detection of complex data relations in big data through Dutch House-Price forecasting using PCA, Independent Component Analysis, Sparse PCA alongside machine learning based techniques such as XGBoost \u0026 Elastic Nets. Potential of mixture models is also explore through mean model combinations. ","excerpt_text":"This study investigates compression and detection of complex data relations in big data through Dutch House-Price forecasting using PCA, Independent Component Analysis, Sparse PCA alongside machine learning based techniques such as XGBoost \u0026 Elastic Nets. Potential of mixture models is also explore through mean model combinations. ","expirydate":-62135596800,"fuzzywordcount":3200,"html":"This study investigates compression and detection of complex data relations in big data through Dutch House-Price forecasting using PCA, Independent Component Analysis, Sparse PCA alongside machine learning based techniques such as XGBoost \u0026 Elastic Nets. Potential of mixture models is also explore through mean model combinations. ","keywords":null,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"d75e0a4f3a1d4a5ad8c4adc8eaef1f21","permalink":"/post/2021_factor_ml_forecasting/","publishdate":"2021-06-01T00:00:00Z","readingtime":15,"relpermalink":"/post/2021_factor_ml_forecasting/","section":"post","summary":"TL:DR The objective of this study is to predict Dutch House prices using macroeconomic variables that were collected from Government open-source databases. Given the high number of explanatory variables relative to the number of observations, we recognise a good fit with parsimonious modelling. These models are characterised by their great explanatory power from minimal resources and are especially valuable in cases of limited or low-frequency data.\nThe methods considered follow Kim \u0026amp; Swanson (2018) hybrid model design, where we combine factor modelling techniques (PCA, ICA, Sparse PCA) and machine learning ensembles (Boosting) and regularization methods (Elastic Net, Ridge regression, LASSO).","tags":["Data Science","Dimension Reduction","Econometrics","Forecasting","Machine Learning"],"title":"PCA Machine Learning Hybrid Models: Real Estate Forecasting","type":"post","url":"/post/2021_factor_ml_forecasting/","weight":0,"wordcount":3122},{"author":null,"categories":["Projects"],"content":"This post briefly introduces deep-learning based reinforcement learning, covering three algorithms: Simple/Standard REINFORCE, Actor-Critic (A2C), and Deep Q-learning (DQN). We evaluate these models on the CartPole-v1 problem (open-source by OpenAI) whilst comparing their game performance, stability, and computational efficiency. The implementation uses Python (PyTorch).","date":1619827200,"description":"This post briefly introduces deep-learning based reinforcement learning, covering three algorithms: Simple/Standard REINFORCE, Actor-Critic (A2C), and Deep Q-learning (DQN). We evaluate these models on the CartPole-v1 problem (open-source by OpenAI) whilst comparing their game performance, stability, and computational efficiency. The implementation uses Python (PyTorch).","dir":"post\\","excerpt_html":"This post briefly introduces deep-learning based reinforcement learning, covering three algorithms: Simple/Standard REINFORCE, Actor-Critic (A2C), and Deep Q-learning (DQN). We evaluate these models on the CartPole-v1 problem (open-source by OpenAI) whilst comparing their game performance, stability, and computational efficiency. The implementation uses Python (PyTorch).","excerpt_text":"This post briefly introduces deep-learning based reinforcement learning, covering three algorithms: Simple/Standard REINFORCE, Actor-Critic (A2C), and Deep Q-learning (DQN). We evaluate these models on the CartPole-v1 problem (open-source by OpenAI) whilst comparing their game performance, stability, and computational efficiency. The implementation uses Python (PyTorch).","expirydate":-62135596800,"fuzzywordcount":2200,"html":"This post briefly introduces deep-learning based reinforcement learning, covering three algorithms: Simple/Standard REINFORCE, Actor-Critic (A2C), and Deep Q-learning (DQN). We evaluate these models on the CartPole-v1 problem (open-source by OpenAI) whilst comparing their game performance, stability, and computational efficiency. The implementation uses Python (PyTorch).","keywords":null,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"75a9c70897d0a624b514048489363098","permalink":"/post/2021_reinforcement/","publishdate":"2021-05-01T00:00:00Z","readingtime":11,"relpermalink":"/post/2021_reinforcement/","section":"post","summary":"TL:DR This post contains a brief introduction to deep-learning based reinforcement learning in the form of simple/standard REINFORCE, Actor-Critic (A2C) and Deep Q-learning (DQN) algorithms with a few extensions. When tackling the CartPole-v1 problem, an open-source playground example by OpenAI, we compare the models in terms of game performance, stability and compute. The code was written using Python with PyTorch.\nIntroduction: Reinforcement Learning (RL) Reinforcement learning (RL) is a machine learning strategy where an agent learns decision-making skills by moving from state to state by interacting with an closed environment without relying on any data.","tags":["Deep Learning","Data Science","Machine Learning","PyTorch","Reinforcement Learning"],"title":"Deep Reinforcement Learning: Game Automation","type":"post","url":"/post/2021_reinforcement/","weight":0,"wordcount":2144},{"author":null,"categories":["Projects"],"content":"This study seeks to distinguish between positive and negative movie reviews using Recurrent Neural Networks (RNNs). In particular, the goal is to leverage their ability to capture complex relations and sequential dependencies in text data. This method is benchmarked against other deep learning implementations and checked for robustness using Python (PyTorch). ","date":1617235200,"description":"This study seeks to distinguish between positive and negative movie reviews using Recurrent Neural Networks (RNNs). In particular, the goal is to leverage their ability to capture complex relations and sequential dependencies in text data. This method is benchmarked against other deep learning implementations and checked for robustness using Python (PyTorch). ","dir":"post\\","excerpt_html":"This study seeks to distinguish between positive and negative movie reviews using Recurrent Neural Networks (RNNs). In particular, the goal is to leverage their ability to capture complex relations and sequential dependencies in text data. This method is benchmarked against other deep learning implementations and checked for robustness using Python (PyTorch). ","excerpt_text":"This study seeks to distinguish between positive and negative movie reviews using Recurrent Neural Networks (RNNs). In particular, the goal is to leverage their ability to capture complex relations and sequential dependencies in text data. This method is benchmarked against other deep learning implementations and checked for robustness using Python (PyTorch). ","expirydate":-62135596800,"fuzzywordcount":1000,"html":"This study seeks to distinguish between positive and negative movie reviews using Recurrent Neural Networks (RNNs). In particular, the goal is to leverage their ability to capture complex relations and sequential dependencies in text data. This method is benchmarked against other deep learning implementations and checked for robustness using Python (PyTorch). ","keywords":null,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"380181ae92fff80ca3cc6902af316792","permalink":"/post/2021_rnn_sentiment_classifier/","publishdate":"2021-04-01T00:00:00Z","readingtime":5,"relpermalink":"/post/2021_rnn_sentiment_classifier/","section":"post","summary":"TL:DR The objective is to accurately identify whether a movie was positively or negatively received through text reviews from IMDb. This is a common NLP challenge that is known as Sentiment Classification. The proposed algorithm is a Recurrent Neural Network (RNN). Especially the ability to capture complex relations and sequential dependencies in text data is what becomes valuable here. In this brief post, a well-known RNN implementation, a LSTM, is benchmarked against other deep learning implementations and checked for robustness.","tags":["Classification","Data Science","Deep Learning","Machine Learning","NLP","PyTorch"],"title":"RNN Sentiment Classification: Movie Reviews","type":"post","url":"/post/2021_rnn_sentiment_classifier/","weight":0,"wordcount":955},{"author":null,"categories":["Projects"],"content":"This article explores the development of a scalable product duplicate detection framework for E-commerce data. Our approach involves combining clustering (Locality-Sensitive Hashing - LSH) with classification, supported by thorough data preprocessing using text analysis, embedding and alternative information compressing techniques.","date":1612137600,"description":"This article explores the development of a scalable product duplicate detection framework for E-commerce data. Our approach involves combining clustering (Locality-Sensitive Hashing - LSH) with classification, supported by thorough data preprocessing using text analysis, embedding and alternative information compressing techniques.","dir":"post\\","excerpt_html":"This article explores the development of a scalable product duplicate detection framework for E-commerce data. Our approach involves combining clustering (Locality-Sensitive Hashing - LSH) with classification, supported by thorough data preprocessing using text analysis, embedding and alternative information compressing techniques.","excerpt_text":"This article explores the development of a scalable product duplicate detection framework for E-commerce data. Our approach involves combining clustering (Locality-Sensitive Hashing - LSH) with classification, supported by thorough data preprocessing using text analysis, embedding and alternative information compressing techniques.","expirydate":-62135596800,"fuzzywordcount":1800,"html":"This article explores the development of a scalable product duplicate detection framework for E-commerce data. Our approach involves combining clustering (Locality-Sensitive Hashing - LSH) with classification, supported by thorough data preprocessing using text analysis, embedding and alternative information compressing techniques.","keywords":null,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"a7c50e3efbadcc16bb1c54d3ed3e34e7","permalink":"/post/2021_lsh_duplicate_detection/","publishdate":"2021-02-01T00:00:00Z","readingtime":9,"relpermalink":"/post/2021_lsh_duplicate_detection/","section":"post","summary":"TL:DR This article explore the development of a scalable product duplicate detection framework for E-commerce data. Our approach involves combining clustering (Locality-Sensitive Hashing - LSH) with classification, supported by thorough data preprocessing using text analysis and NLP techniques.\nThe overall approach is summarised in the following diagram: Context With the ever increasing relevance of online shopping and customers are becoming more comfortable with online platforms with user experience therefore playing a crucial role in driving sales and preventing churn.","tags":["Classification","Clustering","Computer Science","Data Science","Dimension Reduction","NLP"],"title":"Scalable Duplicate Detection \u0026 Text Analysis: Ecommerce Products","type":"post","url":"/post/2021_lsh_duplicate_detection/","weight":0,"wordcount":1709},{"author":null,"categories":null,"content":null,"date":-62135596800,"description":"","dir":"about\\","excerpt_html":null,"excerpt_text":null,"expirydate":-62135596800,"fuzzywordcount":400,"html":null,"keywords":null,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"/about/","publishdate":"0001-01-01T00:00:00Z","readingtime":2,"relpermalink":"/about/","section":"","summary":"About Me Hi - Thanks for stopping by! I\u0026rsquo;m Richie, 22 years old, and an Econometrics and Data Science enthusiast based in the Netherlands. I have 5 years of experience working with data of which 2 years in industry.\nBelow, you\u0026rsquo;ll find a sneak peek into my interests and what fuels my excitement. If you\u0026rsquo;re keen on collaborating, sharing ideas, or simply connecting, feel free to reach out! When it comes to striking interesting conversations, my inbox is always open.","tags":null,"title":"","type":"page","url":"/about/","weight":0,"wordcount":331},{"author":null,"categories":null,"content":null,"date":-62135596800,"description":"","dir":"notes\\","excerpt_html":null,"excerpt_text":null,"expirydate":-62135596800,"fuzzywordcount":100,"html":null,"keywords":null,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1ede8046f9c3a02d422dea7bbf324e64","permalink":"/notes/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/notes/","section":"","summary":"Go 语言学习笔记 Envoy 学习笔记 ","tags":null,"title":"","type":"page","url":"/notes/","weight":0,"wordcount":4},{"author":null,"categories":null,"content":null,"date":-62135596800,"description":"","dir":"search\\","excerpt_html":null,"excerpt_text":null,"expirydate":-62135596800,"fuzzywordcount":100,"html":null,"keywords":null,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8946788897930c0c0c39fbfcd30ff2e4","permalink":"/search/placeholder/","publishdate":"0001-01-01T00:00:00Z","readingtime":1,"relpermalink":"/search/placeholder/","section":"search","summary":"hi","tags":null,"title":"","type":"search","url":"/search/placeholder/","weight":0,"wordcount":1},{"author":null,"categories":null,"content":"Archive of historical posts.","date":-62135596800,"description":"Archive of historical posts.","dir":"archive\\","excerpt_html":"Archive of historical posts.","excerpt_text":"Archive of historical posts.","expirydate":-62135596800,"fuzzywordcount":100,"html":"Archive of historical posts.","keywords":null,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a06e5ce9eca4c3260843078104889780","permalink":"/archive/","publishdate":"0001-01-01T00:00:00Z","readingtime":0,"relpermalink":"/archive/","section":"","summary":"","tags":null,"title":"Posts Archive","type":"archive","url":"/archive/","weight":0,"wordcount":0}]