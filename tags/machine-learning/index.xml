<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Richie Lee</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Richie Lee</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Uplift Modelling: Personalising Discount Campaigns</title>
      <link>/post/2021_uplift/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2021_uplift/</guid>
      <description>TL:DR This post cover an application of Uplift modelling, a methodology that leverages causal inference insights alongside personalisation techniques (XGBoost) to optimise ROI on, in this case, an A/B/n tested marketing campaign. The experiment results can be used to identify target audience to maximise positive conversion and to minimise corresponding costs and campaign-caused churns.
Context When considering targeted campaigns one of the most important questions to ask is, Who is our intended audience?</description>
    </item>
    
    <item>
      <title>PCA Machine Learning Hybrid Models: Real Estate Forecasting</title>
      <link>/post/2021_factor_ml_forecasting/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021_factor_ml_forecasting/</guid>
      <description>TL:DR The objective of this study is to predict Dutch House prices using macroeconomic variables that were collected from Government open-source databases. Given the high number of explanatory variables relative to the number of observations, we recognise a good fit with parsimonious modelling. These models are characterised by their great explanatory power from minimal resources and are especially valuable in cases of limited or low-frequency data.
The methods considered follow Kim &amp;amp; Swanson (2018) hybrid model design, where we combine factor modelling techniques (PCA, ICA, Sparse PCA) and machine learning ensembles (Boosting) and regularization methods (Elastic Net, Ridge regression, LASSO).</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning: Game Automation</title>
      <link>/post/2021_reinforcement/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021_reinforcement/</guid>
      <description>TL:DR This post contains a brief introduction to deep-learning based reinforcement learning in the form of simple/standard REINFORCE, Actor-Critic (A2C) and Deep Q-learning (DQN) algorithms with a few extensions. When tackling the CartPole-v1 problem, an open-source playground example by OpenAI, we compare the models in terms of game performance, stability and compute. The code was written using Python with PyTorch.
Introduction: Reinforcement Learning (RL) Reinforcement learning (RL) is a machine learning strategy where an agent learns decision-making skills by moving from state to state by interacting with an closed environment without relying on any data.</description>
    </item>
    
    <item>
      <title>RNN Sentiment Classification: Movie Reviews</title>
      <link>/post/2021_rnn_sentiment_classifier/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021_rnn_sentiment_classifier/</guid>
      <description>TL:DR The objective is to accurately identify whether a movie was positively or negatively received through text reviews from IMDb. This is a common NLP challenge that is known as Sentiment Classification. The proposed algorithm is a Recurrent Neural Network (RNN). Especially the ability to capture complex relations and sequential dependencies in text data is what becomes valuable here. In this brief post, a well-known RNN implementation, a LSTM, is benchmarked against other deep learning implementations and checked for robustness.</description>
    </item>
    
  </channel>
</rss>
